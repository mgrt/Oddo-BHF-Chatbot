{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09af9587-f041-4a01-8ad1-ef97fe62d9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {\"device\": \"cuda\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "embedding_model = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    ")\n",
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"nous-hermes2:10.7b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6f11281-50df-4eed-9cae-86a0010a8d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unstructured.partition.pdf import partition_pdf\n",
    "from unstructured.chunking.title import chunk_by_title\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_core.documents import Document\n",
    "llm = Ollama(model=\"nous-hermes2:10.7b\")\n",
    "\n",
    "from tqdm import tqdm \n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
    "documents = []\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "# model_name = \"BAAI/bge-m3\"\n",
    "# model_kwargs = {\"device\": \"cuda\"}\n",
    "# encode_kwargs = {\"normalize_embeddings\": True}\n",
    "# embedding_model = HuggingFaceBgeEmbeddings(\n",
    "#     model_name=model_name, model_kwargs=model_kwargs, encode_kwargs=encode_kwargs\n",
    "# )\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10bfecd6-3fc9-4f81-9617-9b4269df26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def buildrag(full_path,persist_directory):\n",
    "    \n",
    "    elements1 = partition_pdf(filename=full_path,\n",
    "                                   regex_metadata={\"Date publication:\": r\"Date publication: (\\d{1,2}/\\d{1,2}/\\d{4})\",\n",
    "                                                    \"Publication date\": r\"Publication date (\\d{1,2}/\\d{1,2}/\\d{4})\"},\n",
    "                                  \n",
    "                                      strategy='hi_res',\n",
    "                                      extract_images_in_pdf=False,\n",
    "                                      hi_res_model_name=\"yolox\",\n",
    "                                      skip_infer_table_types=[],\n",
    "                                      infer_table_structure=True)\n",
    "\n",
    "    tables = [el for el in elements1 if el.category == \"Table\"]\n",
    "    date=''\n",
    "    for i in elements1:\n",
    "        \n",
    "        if i.metadata.regex_metadata: \n",
    "            \n",
    "            \n",
    "            regex_metadata = i.metadata.regex_metadata\n",
    "            \n",
    "            if 'Publication date' in regex_metadata: \n",
    "                \n",
    "                date_info = regex_metadata['Publication date'][0]['text']\n",
    "                date = date_info.split(': ')[-1]\n",
    "           \n",
    "                break  \n",
    "            elif 'Date publication:' in regex_metadata:  \n",
    "                date_info = regex_metadata['Date publication:'][0]['text']\n",
    "                date = date_info.split(': ')[-1]  \n",
    "          \n",
    "                break \n",
    "\n",
    "    # alltable+=tables\n",
    "    print(date)\n",
    "    for element in tqdm(tables, desc=\"Processing Tables\"):\n",
    "        \n",
    "        # prompt_text = \"\"\"Write a concise summary of the following:\n",
    "\n",
    "        # {}\n",
    " \n",
    "        # CONCISE SUMMARY:\"\"\".format(element.text)\n",
    "\n",
    "        metadata = element.metadata.to_dict()\n",
    "        del metadata[\"languages\"]\n",
    "        metadata[\"source\"] = metadata[\"filename\"]\n",
    "        metadata[\"date\"] = date\n",
    "       \n",
    "\n",
    "        summ=chain.invoke([Document(page_content=element.text)])\n",
    "\n",
    "        documents.append(Document(page_content=summ['output_text'], metadata=metadata))        \n",
    "    elements = [el for el in elements1 if el.category != \"Table\"]\n",
    "    chu=chunk_by_title(elements)\n",
    "    # allelem+=chu\n",
    "    \n",
    "    for element in chu:\n",
    "        \n",
    "         metadata = element.metadata.to_dict()\n",
    "         del metadata[\"languages\"]\n",
    "         metadata[\"source\"] = metadata[\"filename\"]\n",
    "         metadata[\"date\"] = date\n",
    "    \n",
    "         documents.append(Document(page_content=element.text, metadata=metadata))\n",
    "    for doc in documents:\n",
    "        \n",
    "        for md in doc.metadata:\n",
    "            \n",
    "            doc.metadata[md] = str(doc.metadata[md])   \n",
    "    \n",
    "    vectorstoresen = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding_model,\n",
    "    persist_directory=persist_directory\n",
    "    )        \n",
    "            \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07690f0-7d0d-4f21-9bfe-353cbd34c0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello my name is malouka\n",
      "el languege howa \n",
      "dkhalet fel partion or image\n",
      "kbal pdf stratigy\n",
      "kamel el  pdf stratigy\n",
      "dkhalet fel test mta stratigy\n",
      "tawa dekhel lel partiti or image local\n",
      "dkhalet le thenya ou ani kaed nhabet ou nimplo\n",
      "el file tla nonee\n",
      "dkhalet lel process_file_with_model\n",
      "kmelt mel file file tla nonee\n",
      "mech chiper\n",
      "khrajet meli mech chiper\n",
      "kamel el if analysisss\n",
      "i'm in merge_inferred_with_extracted_layout\n",
      "kbal el inferred\n",
      "baed el inferred_pages\n",
      "baed el boucle for\n",
      "0\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "1\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "2\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "3\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "4\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "5\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "6\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "7\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "8\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "9\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "10\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "11\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "12\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "13\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "14\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "15\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "16\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "17\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "18\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "19\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "baed el boucle for\n",
      "20\n",
      "khrajet  laka el if\n",
      "dkhalet lel merge_inferred_with_extracted_page \n",
      "khrajet  lel merge_inferred_with_extracted_page \n",
      "------------------------------baed el boucle el final ---------------------------------\n",
      "dkhalel lel process file withe ocr \n",
      "ena tawa bech nconverti\n",
      "full page\n",
      "ena tawa dkhalet fel table\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/table-transformer-structure-recognition were not used when initializing TableTransformerForObjectDetection: ['model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "full page\n",
      "ena tawa dkhalet fel table\n",
      "kamelt lel process file withe ocr \n",
      "Publication date 10/01/2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Tables: 100%|███████████████████████████████████████████████████████████████| 30/30 [04:21<00:00,  8.71s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_path=\"test_pdfs/louka.pdf\"\n",
    "persist_directory = 'test/'\n",
    "buildrag(full_path,persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3905cc57-201e-4fa9-ad3d-d4cf8ec6a257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
